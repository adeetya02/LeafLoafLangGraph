<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LeafLoaf Voice - Conversational AI</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0f0f1e;
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            max-width: 800px;
            width: 100%;
            text-align: center;
        }
        
        h1 {
            font-size: 48px;
            background: linear-gradient(135deg, #64ffda 0%, #63a4ff 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 20px;
        }
        
        .status {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px 30px;
            border-radius: 50px;
            margin: 20px 0;
            font-size: 18px;
            transition: all 0.3s ease;
        }
        
        .status.connected {
            background: rgba(100, 255, 218, 0.2);
            color: #64ffda;
        }
        
        .status.error {
            background: rgba(255, 99, 132, 0.2);
            color: #ff6384;
        }
        
        .controls {
            margin: 40px 0;
        }
        
        button {
            background: linear-gradient(135deg, #64ffda 0%, #63a4ff 100%);
            color: #0f0f1e;
            border: none;
            padding: 15px 40px;
            font-size: 18px;
            font-weight: 600;
            border-radius: 50px;
            cursor: pointer;
            margin: 0 10px;
            transition: all 0.3s ease;
        }
        
        button:hover:not(:disabled) {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(100, 255, 218, 0.3);
        }
        
        button:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .conversation {
            background: rgba(255, 255, 255, 0.05);
            border-radius: 20px;
            padding: 30px;
            min-height: 400px;
            max-height: 600px;
            overflow-y: auto;
            margin-top: 30px;
            text-align: left;
        }
        
        .message {
            margin: 15px 0;
            padding: 15px;
            border-radius: 15px;
            animation: fadeIn 0.5s ease;
        }
        
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(10px);
            }
            to {
                opacity: 1;
                transform: translateY(0);
            }
        }
        
        .user {
            background: rgba(99, 164, 255, 0.2);
            margin-left: 50px;
            border-bottom-right-radius: 5px;
        }
        
        .assistant {
            background: rgba(100, 255, 218, 0.2);
            margin-right: 50px;
            border-bottom-left-radius: 5px;
        }
        
        .system {
            background: rgba(255, 255, 255, 0.1);
            text-align: center;
            font-size: 14px;
            color: #888;
        }
        
        .label {
            font-size: 12px;
            opacity: 0.7;
            margin-bottom: 5px;
        }
        
        #volume-meter {
            width: 100%;
            height: 10px;
            background: rgba(255, 255, 255, 0.1);
            border-radius: 5px;
            margin: 20px 0;
            overflow: hidden;
        }
        
        #volume-level {
            height: 100%;
            background: linear-gradient(90deg, #64ffda 0%, #63a4ff 100%);
            width: 0%;
            transition: width 0.1s ease;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸ›’ LeafLoaf Voice Assistant</h1>
        <p style="opacity: 0.7; margin-bottom: 30px;">Conversational AI for your grocery shopping</p>
        
        <div class="status" id="status">Click Start to begin conversation</div>
        
        <div class="controls">
            <button id="startBtn" onclick="startConversation()">Start Conversation</button>
            <button id="stopBtn" onclick="stopConversation()" disabled>Stop</button>
        </div>
        
        <div id="volume-meter">
            <div id="volume-level"></div>
        </div>
        
        <div class="conversation" id="conversation">
            <div class="message system">Conversation will appear here...</div>
        </div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let source = null;
        let processor = null;
        let stream = null;
        let audioQueue = [];
        let isPlaying = false;
        
        const statusEl = document.getElementById('status');
        const conversationEl = document.getElementById('conversation');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const volumeLevel = document.getElementById('volume-level');
        
        function addMessage(text, type = 'system') {
            const messageEl = document.createElement('div');
            messageEl.className = `message ${type}`;
            
            if (type !== 'system') {
                const label = document.createElement('div');
                label.className = 'label';
                label.textContent = type === 'user' ? 'You' : 'Assistant';
                messageEl.appendChild(label);
            }
            
            const content = document.createElement('div');
            content.textContent = text;
            messageEl.appendChild(content);
            
            conversationEl.appendChild(messageEl);
            conversationEl.scrollTop = conversationEl.scrollHeight;
        }
        
        async function startConversation() {
            try {
                // Clear conversation
                conversationEl.innerHTML = '';
                addMessage('Starting conversation...');
                
                // Get microphone access
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    }
                });
                
                // Setup audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({ sampleRate: 16000 });
                source = audioContext.createMediaStreamSource(stream);
                processor = audioContext.createScriptProcessor(2048, 1, 1);
                
                // Connect to WebSocket - CORRECTED URL
                const wsUrl = `ws://${window.location.host}/api/v1/voice-conv/stream`;
                console.log('Connecting to:', wsUrl);
                
                ws = new WebSocket(wsUrl);
                ws.binaryType = 'arraybuffer';
                
                ws.onopen = () => {
                    console.log('WebSocket connected');
                    statusEl.textContent = 'Connected - Start speaking!';
                    statusEl.className = 'status connected';
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                };
                
                ws.onmessage = (event) => {
                    if (event.data instanceof ArrayBuffer) {
                        // Audio data - play it
                        playAudio(event.data);
                    } else {
                        // JSON message
                        const data = JSON.parse(event.data);
                        handleMessage(data);
                    }
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    statusEl.textContent = 'Connection error';
                    statusEl.className = 'status error';
                    addMessage('Connection error occurred', 'system');
                };
                
                ws.onclose = () => {
                    console.log('WebSocket closed');
                    stopConversation();
                };
                
                // Process audio when WebSocket is ready
                processor.onaudioprocess = (e) => {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        
                        // Show volume level
                        const volume = Math.max(...inputData.map(Math.abs)) * 100;
                        volumeLevel.style.width = `${Math.min(volume * 2, 100)}%`;
                        
                        // Convert to PCM16
                        const pcm16 = convertTo16BitPCM(inputData);
                        ws.send(pcm16);
                    }
                };
                
                // Connect audio nodes
                source.connect(processor);
                processor.connect(audioContext.destination);
                
            } catch (error) {
                console.error('Error starting conversation:', error);
                statusEl.textContent = 'Microphone access denied';
                statusEl.className = 'status error';
                addMessage('Failed to access microphone', 'system');
            }
        }
        
        function stopConversation() {
            statusEl.textContent = 'Disconnected';
            statusEl.className = 'status';
            startBtn.disabled = false;
            stopBtn.disabled = true;
            volumeLevel.style.width = '0%';
            
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            
            if (source) {
                source.disconnect();
                source = null;
            }
            
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (ws) {
                ws.close();
                ws = null;
            }
        }
        
        function handleMessage(data) {
            console.log('Message:', data);
            
            switch (data.type) {
                case 'system':
                    addMessage(data.message, 'system');
                    break;
                    
                case 'transcript':
                    if (data.is_final) {
                        addMessage(data.text, 'user');
                    }
                    break;
                    
                case 'assistant_response':
                    addMessage(data.text, 'assistant');
                    break;
                    
                case 'audio':
                    // Audio data is base64 encoded
                    const audioData = base64ToArrayBuffer(data.data);
                    queueAudio(audioData);
                    break;
                    
                case 'error':
                    addMessage(`Error: ${data.message}`, 'system');
                    break;
            }
        }
        
        function convertTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            let offset = 0;
            
            for (let i = 0; i < float32Array.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            
            return buffer;
        }
        
        function base64ToArrayBuffer(base64) {
            const binaryString = window.atob(base64);
            const bytes = new Uint8Array(binaryString.length);
            for (let i = 0; i < binaryString.length; i++) {
                bytes[i] = binaryString.charCodeAt(i);
            }
            return bytes.buffer;
        }
        
        function queueAudio(audioData) {
            audioQueue.push(audioData);
            if (!isPlaying) {
                playNextAudio();
            }
        }
        
        async function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                return;
            }
            
            isPlaying = true;
            const audioData = audioQueue.shift();
            
            try {
                const audioBuffer = await audioContext.decodeAudioData(audioData);
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                
                source.onended = () => {
                    playNextAudio();
                };
                
                source.start();
            } catch (error) {
                console.error('Error playing audio:', error);
                playNextAudio();
            }
        }
        
        async function playAudio(audioData) {
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
            }
            
            try {
                const audioBuffer = await audioContext.decodeAudioData(audioData);
                const source = audioContext.createBufferSource();
                source.buffer = audioBuffer;
                source.connect(audioContext.destination);
                source.start();
            } catch (error) {
                console.error('Error playing audio:', error);
            }
        }
    </script>
</body>
</html>