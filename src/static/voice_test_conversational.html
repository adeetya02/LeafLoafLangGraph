<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LeafLoaf Voice Test - Conversational</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            background: #0f0f1e;
            color: #ffffff;
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            max-width: 800px;
            width: 100%;
            text-align: center;
        }
        
        h1 {
            font-size: 48px;
            background: linear-gradient(135deg, #64ffda 0%, #63a4ff 100%);
            -webkit-background-clip: text;
            -webkit-text-fill-color: transparent;
            margin-bottom: 20px;
        }
        
        .status {
            background: rgba(255, 255, 255, 0.1);
            padding: 15px 30px;
            border-radius: 50px;
            margin: 20px 0;
            font-size: 18px;
        }
        
        .status.connected {
            background: rgba(100, 255, 218, 0.2);
            color: #64ffda;
        }
        
        .status.error {
            background: rgba(255, 100, 100, 0.2);
            color: #ff6464;
        }
        
        .transcript-box {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 15px;
            padding: 30px;
            margin: 20px 0;
            min-height: 150px;
            text-align: left;
        }
        
        .transcript {
            color: #8892b0;
            line-height: 1.6;
        }
        
        .transcript.final {
            color: #ffffff;
            font-weight: 500;
        }
        
        .response {
            color: #64ffda;
            margin-top: 15px;
            padding-top: 15px;
            border-top: 1px solid rgba(255, 255, 255, 0.1);
        }
        
        .btn {
            background: linear-gradient(135deg, #64ffda 0%, #63a4ff 100%);
            border: none;
            color: #0f0f1e;
            padding: 15px 40px;
            font-size: 18px;
            font-weight: 600;
            border-radius: 50px;
            cursor: pointer;
            transition: all 0.3s ease;
            margin: 10px;
        }
        
        .btn:hover {
            transform: translateY(-2px);
            box-shadow: 0 10px 30px rgba(100, 255, 218, 0.3);
        }
        
        .btn:active {
            transform: translateY(0);
        }
        
        .btn:disabled {
            opacity: 0.5;
            cursor: not-allowed;
        }
        
        .products {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(250px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }
        
        .product {
            background: rgba(255, 255, 255, 0.05);
            border: 1px solid rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 20px;
            text-align: left;
        }
        
        .product h4 {
            color: #64ffda;
            margin-bottom: 10px;
        }
        
        .product .price {
            font-size: 24px;
            font-weight: 600;
            color: #63a4ff;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ LeafLoaf Voice</h1>
        <p style="color: #8892b0; margin-bottom: 30px;">Real-time conversational shopping</p>
        
        <div id="status" class="status">Click Start to begin</div>
        
        <div class="transcript-box">
            <div id="transcript" class="transcript">
                Waiting to start...
            </div>
            <div id="response" class="response" style="display: none;"></div>
        </div>
        
        <div class="controls">
            <button id="startBtn" class="btn" onclick="startConversation()">
                Start Conversation
            </button>
            <button id="stopBtn" class="btn" onclick="stopConversation()" disabled>
                Stop
            </button>
        </div>
        
        <div id="products" class="products"></div>
    </div>

    <script>
        let ws = null;
        let audioContext = null;
        let processor = null;
        let source = null;
        let stream = null;
        
        // UI elements
        const statusEl = document.getElementById('status');
        const transcriptEl = document.getElementById('transcript');
        const responseEl = document.getElementById('response');
        const productsEl = document.getElementById('products');
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        
        async function startConversation() {
            try {
                // Get microphone access
                stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Create audio context
                audioContext = new AudioContext({ sampleRate: 16000 });
                source = audioContext.createMediaStreamSource(stream);
                processor = audioContext.createScriptProcessor(4096, 1, 1);
                
                // Connect to WebSocket
                const sessionId = Math.random().toString(36).substring(7);
                const wsUrl = `ws://${window.location.host}/api/v1/voice-streaming/websocket/conversational`;
                console.log('Connecting to:', wsUrl);
                
                ws = new WebSocket(wsUrl);
                ws.binaryType = 'arraybuffer';
                
                ws.onopen = () => {
                    console.log('WebSocket connected');
                    statusEl.textContent = 'Connected - Start speaking!';
                    statusEl.className = 'status connected';
                    startBtn.disabled = true;
                    stopBtn.disabled = false;
                };
                
                ws.onmessage = (event) => {
                    if (event.data instanceof ArrayBuffer) {
                        // Audio data - play it
                        playAudio(event.data);
                    } else {
                        // JSON message
                        const data = JSON.parse(event.data);
                        handleMessage(data);
                    }
                };
                
                ws.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    statusEl.textContent = 'Connection error';
                    statusEl.className = 'status error';
                };
                
                ws.onclose = () => {
                    console.log('WebSocket closed');
                    stopConversation();
                };
                
                // Process audio when WebSocket is ready
                processor.onaudioprocess = (e) => {
                    if (ws && ws.readyState === WebSocket.OPEN) {
                        const inputData = e.inputBuffer.getChannelData(0);
                        const pcm16 = convertTo16BitPCM(inputData);
                        ws.send(pcm16);
                    }
                };
                
                // Connect audio nodes
                source.connect(processor);
                processor.connect(audioContext.destination);
                
            } catch (error) {
                console.error('Error starting conversation:', error);
                statusEl.textContent = 'Microphone access denied';
                statusEl.className = 'status error';
            }
        }
        
        function stopConversation() {
            // Close WebSocket
            if (ws) {
                ws.close();
                ws = null;
            }
            
            // Stop audio
            if (processor) {
                processor.disconnect();
                processor = null;
            }
            if (source) {
                source.disconnect();
                source = null;
            }
            if (stream) {
                stream.getTracks().forEach(track => track.stop());
                stream = null;
            }
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            // Update UI
            statusEl.textContent = 'Disconnected';
            statusEl.className = 'status';
            startBtn.disabled = false;
            stopBtn.disabled = true;
        }
        
        function handleMessage(data) {
            console.log('Message:', data);
            
            switch (data.type) {
                case 'deepgram_connected':
                    statusEl.textContent = 'Ready - Start speaking!';
                    break;
                    
                case 'interim_transcript':
                    transcriptEl.innerHTML = `<span class="transcript">${data.text}</span>`;
                    break;
                    
                case 'acknowledgment':
                    responseEl.textContent = data.text;
                    responseEl.style.display = 'block';
                    break;
                    
                case 'response':
                    transcriptEl.innerHTML = `<span class="transcript final">You: ${data.query || 'Query'}</span>`;
                    responseEl.innerHTML = `Assistant: ${data.text}`;
                    responseEl.style.display = 'block';
                    
                    // Show products if available
                    if (data.products && data.products.length > 0) {
                        displayProducts(data.products);
                    }
                    break;
                    
                case 'error':
                    statusEl.textContent = `Error: ${data.message}`;
                    statusEl.className = 'status error';
                    break;
            }
        }
        
        function displayProducts(products) {
            productsEl.innerHTML = products.map(p => `
                <div class="product">
                    <h4>${p.product_name || p.name}</h4>
                    <p>${p.product_description || ''}</p>
                    <div class="price">$${(p.price || 0).toFixed(2)}</div>
                    <small>${p.supplier || ''}</small>
                </div>
            `).join('');
        }
        
        function convertTo16BitPCM(float32Array) {
            const buffer = new ArrayBuffer(float32Array.length * 2);
            const view = new DataView(buffer);
            let offset = 0;
            for (let i = 0; i < float32Array.length; i++, offset += 2) {
                const s = Math.max(-1, Math.min(1, float32Array[i]));
                view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
            }
            return buffer;
        }
        
        function playAudio(audioData) {
            // For now, just log that we received audio
            console.log('Received audio data:', audioData.byteLength, 'bytes');
            // TODO: Implement audio playback
        }
    </script>
</body>
</html>