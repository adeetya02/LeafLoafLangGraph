<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LeafLoaf Voice Assistant</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, Cantarell, sans-serif;
            background: linear-gradient(135deg, #f5f5f5 0%, #e8f5e9 100%);
            min-height: 100vh;
            display: flex;
            align-items: center;
            justify-content: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 10px 40px rgba(0,0,0,0.1);
            max-width: 600px;
            width: 100%;
            padding: 40px;
            text-align: center;
        }
        
        .logo {
            font-size: 3em;
            margin-bottom: 20px;
        }
        
        h1 {
            color: #2e7d32;
            margin-bottom: 10px;
            font-weight: 600;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 40px;
        }
        
        .mic-container {
            position: relative;
            margin: 40px auto;
            width: 120px;
            height: 120px;
        }
        
        .mic-button {
            width: 100%;
            height: 100%;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #4caf50 0%, #2e7d32 100%);
            color: white;
            font-size: 48px;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
            box-shadow: 0 4px 20px rgba(76, 175, 80, 0.3);
        }
        
        .mic-button:hover {
            transform: scale(1.05);
            box-shadow: 0 6px 30px rgba(76, 175, 80, 0.4);
        }
        
        .mic-button.listening {
            background: linear-gradient(135deg, #f44336 0%, #c62828 100%);
            animation: pulse 1.5s infinite;
        }
        
        .mic-button.processing {
            background: linear-gradient(135deg, #ff9800 0%, #f57c00 100%);
            animation: spin 1s linear infinite;
        }
        
        @keyframes pulse {
            0% {
                box-shadow: 0 0 0 0 rgba(244, 67, 54, 0.4);
            }
            70% {
                box-shadow: 0 0 0 20px rgba(244, 67, 54, 0);
            }
            100% {
                box-shadow: 0 0 0 0 rgba(244, 67, 54, 0);
            }
        }
        
        @keyframes spin {
            from {
                transform: rotate(0deg);
            }
            to {
                transform: rotate(360deg);
            }
        }
        
        .status {
            margin-top: 20px;
            font-weight: 500;
            color: #666;
            min-height: 24px;
        }
        
        .transcript-container {
            margin-top: 40px;
            text-align: left;
        }
        
        .transcript-label {
            font-weight: 600;
            color: #333;
            margin-bottom: 10px;
        }
        
        .transcript {
            background: #f5f5f5;
            padding: 20px;
            border-radius: 10px;
            min-height: 100px;
            color: #333;
            font-size: 16px;
            line-height: 1.5;
        }
        
        .transcript.interim {
            color: #999;
            font-style: italic;
        }
        
        .response-container {
            margin-top: 20px;
            text-align: left;
        }
        
        .response-label {
            font-weight: 600;
            color: #2e7d32;
            margin-bottom: 10px;
        }
        
        .response {
            background: #e8f5e9;
            padding: 20px;
            border-radius: 10px;
            min-height: 100px;
            color: #1b5e20;
            font-size: 16px;
            line-height: 1.5;
        }
        
        .error {
            color: #d32f2f;
            background: #ffebee;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
        }
        
        .instructions {
            background: #e3f2fd;
            padding: 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            color: #1565c0;
            font-size: 14px;
        }
        
        .connection-status {
            position: absolute;
            top: 20px;
            right: 20px;
            display: flex;
            align-items: center;
            gap: 8px;
            font-size: 14px;
            color: #666;
        }
        
        .status-dot {
            width: 10px;
            height: 10px;
            border-radius: 50%;
            background: #ccc;
        }
        
        .status-dot.connected {
            background: #4caf50;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="connection-status">
            <span class="status-dot" id="connectionDot"></span>
            <span id="connectionText">Disconnected</span>
        </div>
        
        <div class="logo">ðŸ¥¬</div>
        <h1>LeafLoaf Voice Assistant</h1>
        <p class="subtitle">Your AI-powered grocery shopping companion</p>
        
        <div class="instructions">
            ðŸŽ¤ This is a TRUE conversational AI - just click the mic and start talking naturally!
            No need to hold the button. I'll listen continuously and respond like a real conversation.
        </div>
        
        <div class="mic-container">
            <button class="mic-button" id="micButton">
                <span id="micIcon">ðŸŽ¤</span>
            </button>
        </div>
        
        <div class="status" id="status">Click the microphone to start</div>
        
        <div class="transcript-container">
            <div class="transcript-label">You said:</div>
            <div class="transcript" id="transcript">Waiting for speech...</div>
        </div>
        
        <div class="response-container">
            <div class="response-label">LeafLoaf says:</div>
            <div class="response" id="response">I'm ready to help you with your grocery shopping!</div>
        </div>
        
        <div id="error" class="error" style="display: none;"></div>
    </div>
    
    <script>
        // Global state
        let websocket = null;
        let mediaRecorder = null;
        let audioStream = null;
        let isListening = false;
        let audioContext = null;
        let scriptProcessor = null;
        
        // DOM elements
        const micButton = document.getElementById('micButton');
        const micIcon = document.getElementById('micIcon');
        const status = document.getElementById('status');
        const transcript = document.getElementById('transcript');
        const response = document.getElementById('response');
        const error = document.getElementById('error');
        const connectionDot = document.getElementById('connectionDot');
        const connectionText = document.getElementById('connectionText');
        
        // WebSocket URL - update this based on your deployment
        const WS_URL = window.location.protocol === 'https:' 
            ? `wss://${window.location.host}/api/v1/voice-streaming/websocket/conversational`
            : `ws://localhost:8080/api/v1/voice-streaming/websocket/conversational`;
        
        // Initialize WebSocket connection
        async function connectWebSocket() {
            try {
                websocket = new WebSocket(WS_URL);
                
                websocket.onopen = () => {
                    console.log('WebSocket connected');
                    connectionDot.classList.add('connected');
                    connectionText.textContent = 'Connected';
                    status.textContent = 'Connected - Click microphone to start';
                    hideError();
                };
                
                websocket.onmessage = (event) => {
                    const data = JSON.parse(event.data);
                    handleWebSocketMessage(data);
                };
                
                websocket.onerror = (err) => {
                    console.error('WebSocket error:', err);
                    showError('Connection error. Please refresh the page.');
                };
                
                websocket.onclose = () => {
                    console.log('WebSocket disconnected');
                    connectionDot.classList.remove('connected');
                    connectionText.textContent = 'Disconnected';
                    status.textContent = 'Disconnected - Reconnecting...';
                    
                    // Attempt to reconnect after 2 seconds
                    setTimeout(connectWebSocket, 2000);
                };
                
            } catch (err) {
                console.error('Failed to connect:', err);
                showError('Failed to connect to server. Please check your connection.');
            }
        }
        
        // Handle incoming WebSocket messages
        function handleWebSocketMessage(data) {
            switch (data.type) {
                case 'deepgram_connected':
                    status.textContent = 'Ready to listen...';
                    break;
                    
                case 'interim_transcript':
                    transcript.textContent = data.text;
                    transcript.classList.add('interim');
                    if (data.is_final) {
                        transcript.classList.remove('interim');
                    }
                    break;
                    
                case 'processing':
                    status.textContent = 'Processing your request...';
                    micButton.classList.add('processing');
                    break;
                    
                case 'response':
                    status.textContent = 'Response received';
                    response.textContent = data.text;
                    micButton.classList.remove('processing');
                    
                    // Optionally show search results
                    if (data.search_results && data.search_results.products) {
                        const productCount = data.search_results.products.length;
                        response.textContent += `\n\n(Found ${productCount} products)`;
                    }
                    break;
                    
                case 'error':
                    showError(data.message);
                    micButton.classList.remove('processing');
                    break;
            }
        }
        
        // Start continuous listening
        async function startListening() {
            try {
                // Get microphone access
                audioStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 16000,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Create audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                const source = audioContext.createMediaStreamSource(audioStream);
                scriptProcessor = audioContext.createScriptProcessor(4096, 1, 1);
                
                scriptProcessor.onaudioprocess = (event) => {
                    if (!isListening) return;
                    
                    const inputData = event.inputBuffer.getChannelData(0);
                    const pcmData = convertFloat32ToInt16(inputData);
                    
                    if (websocket && websocket.readyState === WebSocket.OPEN) {
                        websocket.send(pcmData);
                    }
                };
                
                source.connect(scriptProcessor);
                scriptProcessor.connect(audioContext.destination);
                
                isListening = true;
                micButton.classList.add('listening');
                micIcon.textContent = 'ðŸ”´';
                status.textContent = 'Listening... (click to stop)';
                transcript.textContent = 'Listening...';
                
            } catch (err) {
                console.error('Failed to start listening:', err);
                showError('Failed to access microphone. Please check permissions.');
            }
        }
        
        // Stop listening
        function stopListening() {
            isListening = false;
            micButton.classList.remove('listening');
            micIcon.textContent = 'ðŸŽ¤';
            status.textContent = 'Click microphone to start';
            
            if (scriptProcessor) {
                scriptProcessor.disconnect();
                scriptProcessor = null;
            }
            
            if (audioContext) {
                audioContext.close();
                audioContext = null;
            }
            
            if (audioStream) {
                audioStream.getTracks().forEach(track => track.stop());
                audioStream = null;
            }
        }
        
        // Convert Float32 to Int16 for Deepgram
        function convertFloat32ToInt16(buffer) {
            const l = buffer.length;
            const result = new Int16Array(l);
            
            for (let i = 0; i < l; i++) {
                const s = Math.max(-1, Math.min(1, buffer[i]));
                result[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
            }
            
            return result.buffer;
        }
        
        // Error handling
        function showError(message) {
            error.textContent = message;
            error.style.display = 'block';
        }
        
        function hideError() {
            error.style.display = 'none';
        }
        
        // Microphone button click handler
        micButton.addEventListener('click', () => {
            if (!websocket || websocket.readyState !== WebSocket.OPEN) {
                showError('Not connected to server. Please wait...');
                return;
            }
            
            if (isListening) {
                stopListening();
            } else {
                startListening();
            }
        });
        
        // Send periodic pings to keep connection alive
        setInterval(() => {
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.send(JSON.stringify({ type: 'ping' }));
            }
        }, 30000);
        
        // Initialize on page load
        window.addEventListener('load', () => {
            connectWebSocket();
        });
        
        // Cleanup on page unload
        window.addEventListener('beforeunload', () => {
            stopListening();
            if (websocket) {
                websocket.close();
            }
        });
    </script>
</body>
</html>