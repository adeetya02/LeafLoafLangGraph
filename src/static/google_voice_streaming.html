<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Voice Streaming Demo</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: #f5f5f5;
        }
        .container {
            background: white;
            border-radius: 12px;
            padding: 30px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #4285f4;
            text-align: center;
        }
        .controls {
            display: flex;
            gap: 10px;
            justify-content: center;
            margin: 30px 0;
        }
        button {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 16px;
            cursor: pointer;
            transition: all 0.3s;
        }
        .primary {
            background: #4285f4;
            color: white;
        }
        .primary:hover {
            background: #3367d6;
        }
        .primary:disabled {
            background: #ccc;
        }
        .stop {
            background: #ea4335;
            color: white;
        }
        .stop:hover {
            background: #d33b2c;
        }
        .status {
            text-align: center;
            padding: 10px;
            margin: 20px 0;
            border-radius: 8px;
            font-weight: 500;
        }
        .connected {
            background: #e8f5e9;
            color: #2e7d32;
        }
        .disconnected {
            background: #ffebee;
            color: #c62828;
        }
        .streaming {
            background: #e3f2fd;
            color: #1565c0;
            animation: pulse 2s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        .transcript-container {
            border: 1px solid #e0e0e0;
            border-radius: 8px;
            padding: 20px;
            margin: 20px 0;
            min-height: 150px;
            background: #fafafa;
        }
        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 6px;
        }
        .user {
            background: #e3f2fd;
            text-align: right;
        }
        .assistant {
            background: #e8f5e9;
        }
        .interim {
            color: #666;
            font-style: italic;
        }
        .final {
            color: #000;
            font-weight: 500;
        }
        .error {
            background: #ffebee;
            color: #c62828;
        }
        .visualizer {
            height: 100px;
            background: #f0f0f0;
            border-radius: 8px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            overflow: hidden;
        }
        .bar {
            width: 4px;
            height: 50%;
            background: #4285f4;
            margin: 0 2px;
            transition: height 0.1s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Google Voice Streaming Demo</h1>
        
        <div class="status disconnected" id="status">Disconnected</div>
        
        <div class="controls">
            <button class="primary" id="connectBtn" onclick="toggleConnection()">Connect</button>
            <button class="primary" id="startBtn" onclick="startStreaming()" disabled>Start Speaking</button>
            <button class="stop" id="stopBtn" onclick="stopStreaming()" disabled>Stop</button>
        </div>
        
        <div class="visualizer" id="visualizer">
            <div id="bars"></div>
        </div>
        
        <div class="transcript-container" id="transcript">
            <div class="message assistant">Ready to start. Click Connect, then Start Speaking.</div>
        </div>
    </div>

    <script>
        let ws = null;
        let mediaRecorder = null;
        let audioContext = null;
        let analyser = null;
        let microphone = null;
        let isStreaming = false;
        let animationId = null;

        function updateStatus(text, className) {
            const status = document.getElementById('status');
            status.textContent = text;
            status.className = 'status ' + className;
        }

        function addMessage(text, type = 'assistant', isFinal = true) {
            const container = document.getElementById('transcript');
            const message = document.createElement('div');
            message.className = `message ${type} ${isFinal ? 'final' : 'interim'}`;
            message.textContent = text;
            
            // Update last interim or add new
            const lastMessage = container.lastElementChild;
            if (!isFinal && lastMessage && lastMessage.classList.contains('interim')) {
                lastMessage.textContent = text;
            } else {
                container.appendChild(message);
            }
            
            container.scrollTop = container.scrollHeight;
        }

        async function toggleConnection() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.close();
            } else {
                connect();
            }
        }

        function connect() {
            const wsUrl = 'ws://localhost:8080/api/v1/voice/google-ws/stream?language=en-US';
            
            ws = new WebSocket(wsUrl);
            
            ws.onopen = () => {
                updateStatus('Connected', 'connected');
                document.getElementById('connectBtn').textContent = 'Disconnect';
                document.getElementById('startBtn').disabled = false;
                addMessage('Connected! Click "Start Speaking" to begin.', 'assistant');
            };
            
            ws.onmessage = (event) => {
                const data = JSON.parse(event.data);
                
                switch (data.type) {
                    case 'connected':
                        console.log('WebSocket connected');
                        break;
                        
                    case 'transcript':
                        if (data.text) {
                            addMessage(data.text, 'user', data.is_final);
                        }
                        break;
                        
                    case 'response':
                        addMessage(data.text, 'assistant');
                        if (data.audio) {
                            playAudio(data.audio);
                        }
                        break;
                        
                    case 'error':
                        addMessage(`Error: ${data.message}`, 'error');
                        break;
                }
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('Connection Error', 'disconnected');
            };
            
            ws.onclose = () => {
                updateStatus('Disconnected', 'disconnected');
                document.getElementById('connectBtn').textContent = 'Connect';
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = true;
                if (isStreaming) {
                    stopStreaming();
                }
            };
        }

        async function startStreaming() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        channelCount: 1,
                        sampleRate: 48000,
                        sampleSize: 16,
                        echoCancellation: true,
                        noiseSuppression: true
                    } 
                });
                
                // Set up audio context for visualization
                audioContext = new AudioContext();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                microphone.connect(analyser);
                analyser.fftSize = 256;
                
                // Start visualization
                visualize();
                
                // Set up media recorder
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm;codecs=opus'
                });
                
                mediaRecorder.ondataavailable = async (event) => {
                    if (event.data.size > 0 && ws && ws.readyState === WebSocket.OPEN) {
                        const reader = new FileReader();
                        reader.onload = () => {
                            const base64 = reader.result.split(',')[1];
                            ws.send(JSON.stringify({
                                type: 'audio',
                                data: base64
                            }));
                        };
                        reader.readAsDataURL(event.data);
                    }
                };
                
                // Send start message
                ws.send(JSON.stringify({ type: 'start_streaming' }));
                
                // Start recording with timeslice for streaming
                mediaRecorder.start(100); // Send data every 100ms
                
                isStreaming = true;
                updateStatus('Streaming - Speak now!', 'streaming');
                document.getElementById('startBtn').disabled = true;
                document.getElementById('stopBtn').disabled = false;
                
                addMessage('Listening...', 'assistant');
                
            } catch (error) {
                console.error('Error accessing microphone:', error);
                addMessage('Error: Could not access microphone', 'error');
            }
        }

        function stopStreaming() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                mediaRecorder.stream.getTracks().forEach(track => track.stop());
            }
            
            if (ws && ws.readyState === WebSocket.OPEN) {
                ws.send(JSON.stringify({ type: 'stop_streaming' }));
            }
            
            if (animationId) {
                cancelAnimationFrame(animationId);
            }
            
            if (audioContext) {
                audioContext.close();
            }
            
            isStreaming = false;
            updateStatus('Connected', 'connected');
            document.getElementById('startBtn').disabled = false;
            document.getElementById('stopBtn').disabled = true;
            
            // Clear visualizer
            document.getElementById('bars').innerHTML = '';
        }

        function visualize() {
            const bufferLength = analyser.frequencyBinCount;
            const dataArray = new Uint8Array(bufferLength);
            
            const bars = document.getElementById('bars');
            bars.innerHTML = '';
            
            // Create bars
            for (let i = 0; i < 50; i++) {
                const bar = document.createElement('div');
                bar.className = 'bar';
                bars.appendChild(bar);
            }
            
            const barElements = bars.getElementsByClassName('bar');
            
            function draw() {
                animationId = requestAnimationFrame(draw);
                
                analyser.getByteFrequencyData(dataArray);
                
                for (let i = 0; i < barElements.length; i++) {
                    const value = dataArray[i * 2];
                    const percent = value / 255;
                    barElements[i].style.height = `${Math.max(10, percent * 100)}%`;
                }
            }
            
            draw();
        }

        function playAudio(base64Audio) {
            const audio = new Audio('data:audio/mp3;base64,' + base64Audio);
            audio.play().catch(e => console.error('Error playing audio:', e));
        }

        // Auto-connect on load
        window.addEventListener('load', () => {
            // Uncomment to auto-connect
            // setTimeout(connect, 500);
        });
    </script>
</body>
</html>