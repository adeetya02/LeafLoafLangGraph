<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Google Voice Test - Simplified</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background: #f0f0f0;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0,0,0,0.1);
        }
        h1 {
            color: #333;
            text-align: center;
        }
        .controls {
            display: flex;
            justify-content: center;
            gap: 20px;
            margin: 30px 0;
        }
        button {
            padding: 15px 30px;
            font-size: 18px;
            cursor: pointer;
            border: none;
            border-radius: 5px;
            transition: all 0.3s;
        }
        #startBtn {
            background: #4CAF50;
            color: white;
        }
        #startBtn:hover {
            background: #45a049;
        }
        #startBtn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        #status {
            text-align: center;
            padding: 20px;
            background: #f5f5f5;
            border-radius: 5px;
            margin: 20px 0;
            font-weight: bold;
        }
        #status.connected {
            background: #d4edda;
            color: #155724;
        }
        #status.error {
            background: #f8d7da;
            color: #721c24;
        }
        #messages {
            max-height: 400px;
            overflow-y: auto;
            padding: 20px;
            background: #f9f9f9;
            border-radius: 5px;
            margin-top: 20px;
            border: 1px solid #ddd;
        }
        .message {
            margin: 10px 0;
            padding: 10px;
            border-radius: 5px;
            background: #e9ecef;
        }
        .message.transcript {
            background: #cfe2ff;
            border-left: 4px solid #0d6efd;
        }
        .message.error {
            background: #f8d7da;
            border-left: 4px solid #dc3545;
        }
        .confidence {
            color: #666;
            font-size: 0.9em;
            margin-left: 10px;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ðŸŽ¤ Google STT Test - Simplified</h1>
        <p style="text-align: center; color: #666;">Testing simplified Google Speech-to-Text streaming</p>
        
        <div class="controls">
            <button id="startBtn" onclick="startTest()">Start Test</button>
        </div>
        
        <div id="status">Click "Start Test" to begin</div>
        
        <div id="messages"></div>
    </div>
    
    <script>
        let websocket = null;
        let mediaStream = null;
        let audioContext = null;
        let isRecording = false;
        
        function updateStatus(message, type = 'info') {
            const statusEl = document.getElementById('status');
            statusEl.textContent = message;
            statusEl.className = type;
        }
        
        function addMessage(content, type = 'info') {
            const messagesEl = document.getElementById('messages');
            const messageEl = document.createElement('div');
            messageEl.className = `message ${type}`;
            messageEl.innerHTML = content;
            messagesEl.appendChild(messageEl);
            messagesEl.scrollTop = messagesEl.scrollHeight;
        }
        
        async function startTest() {
            try {
                document.getElementById('startBtn').disabled = true;
                updateStatus('Requesting microphone access...', 'info');
                
                // Get microphone
                mediaStream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        sampleRate: 16000,
                        channelCount: 1,
                        echoCancellation: true,
                        noiseSuppression: true,
                        autoGainControl: true
                    } 
                });
                
                // Initialize audio context
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 16000
                });
                
                updateStatus('Connecting to test endpoint...', 'info');
                
                // Connect to test WebSocket
                const protocol = window.location.protocol === 'https:' ? 'wss:' : 'ws:';
                const wsUrl = `${protocol}//${window.location.host}/api/v1/google-test/ws`;
                
                websocket = new WebSocket(wsUrl);
                
                websocket.onopen = () => {
                    updateStatus('Connected! Speak for 2-3 seconds...', 'connected');
                    addMessage('WebSocket connected to test endpoint', 'info');
                    
                    // Start recording and streaming
                    startRecording();
                };
                
                websocket.onmessage = (event) => {
                    try {
                        const message = JSON.parse(event.data);
                        console.log('Received:', message);
                        
                        if (message.type === 'connected') {
                            addMessage(`âœ… ${message.message}`, 'info');
                        } else if (message.type === 'transcript') {
                            const confidence = message.confidence ? 
                                `<span class="confidence">(${Math.round(message.confidence * 100)}% confidence)</span>` : '';
                            addMessage(`ðŸŽ¤ Transcript: "${message.transcript}" ${confidence}`, 'transcript');
                            
                            if (message.is_final) {
                                addMessage('âœ… Final transcript received!', 'info');
                                stopRecording();
                            }
                        } else if (message.type === 'error') {
                            addMessage(`âŒ Error: ${message.message}`, 'error');
                            updateStatus('Error occurred', 'error');
                            stopRecording();
                        }
                    } catch (e) {
                        console.error('Parse error:', e);
                    }
                };
                
                websocket.onerror = (error) => {
                    console.error('WebSocket error:', error);
                    updateStatus('Connection error', 'error');
                    addMessage('âŒ WebSocket error', 'error');
                };
                
                websocket.onclose = () => {
                    updateStatus('Test completed', 'info');
                    stopRecording();
                    document.getElementById('startBtn').disabled = false;
                };
                
            } catch (error) {
                console.error('Error:', error);
                updateStatus('Failed to start test', 'error');
                addMessage(`âŒ Error: ${error.message}`, 'error');
                document.getElementById('startBtn').disabled = false;
            }
        }
        
        function startRecording() {
            const source = audioContext.createMediaStreamSource(mediaStream);
            const processor = audioContext.createScriptProcessor(2048, 1, 1);
            
            let totalBytesSent = 0;
            
            processor.onaudioprocess = (event) => {
                if (!isRecording || !websocket || websocket.readyState !== WebSocket.OPEN) return;
                
                const inputData = event.inputBuffer.getChannelData(0);
                
                // Convert float32 to int16
                const output = new Int16Array(inputData.length);
                for (let i = 0; i < inputData.length; i++) {
                    const s = Math.max(-1, Math.min(1, inputData[i]));
                    output[i] = s < 0 ? s * 0x8000 : s * 0x7FFF;
                }
                
                // Send audio
                websocket.send(output.buffer);
                totalBytesSent += output.buffer.byteLength;
                
                // Log progress
                if (totalBytesSent % 10000 < 2048) {
                    console.log(`Sent ${Math.round(totalBytesSent / 1000)}KB of audio`);
                }
            };
            
            source.connect(processor);
            processor.connect(audioContext.destination);
            
            isRecording = true;
            console.log('Recording started');
        }
        
        function stopRecording() {
            isRecording = false;
            
            if (mediaStream) {
                mediaStream.getTracks().forEach(track => track.stop());
                mediaStream = null;
            }
            
            if (audioContext && audioContext.state !== 'closed') {
                audioContext.close();
                audioContext = null;
            }
            
            if (websocket && websocket.readyState === WebSocket.OPEN) {
                websocket.close();
                websocket = null;
            }
        }
    </script>
</body>
</html>